{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXOkw8ggO9bJE9Sm6NAeRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmnnf/Book_Store_app_with_filter/blob/main/vehicle/detection/vehicle_detection_93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq3cK5ayIZx0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EfficientNet-B4 + GeM + ArcFace\n",
        "â€£ explicit train / valid / test klasÃ¶rleri\n",
        "\"\"\"\n",
        "\n",
        "import os, random, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
        "import torchvision.transforms as T, timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1) Katmanlar\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3.0, eps=1e-6):\n",
        "        super().__init__(); self.p = nn.Parameter(torch.ones(1)*p); self.eps = eps\n",
        "    def forward(self, x):\n",
        "        x = x.clamp(min=self.eps).pow(self.p)\n",
        "        return F.avg_pool2d(x, (x.size(-2), x.size(-1))).pow(1./self.p)[:, :, 0, 0]\n",
        "\n",
        "try:\n",
        "    from timm.layers import ArcMarginProduct\n",
        "except ImportError:                   # timm<0.8 fallback\n",
        "    class ArcMarginProduct(nn.Module):\n",
        "        def __init__(self, in_f, out_f, s=30., m=0.40):\n",
        "            super().__init__(); self.weight = nn.Parameter(torch.randn(out_f, in_f))\n",
        "            self.s, self.m = s, m\n",
        "        def forward(self, x, y):      # y kullanÄ±lmÄ±yor (ArcFace yerine softmax)\n",
        "            return self.s * F.linear(F.normalize(x), F.normalize(self.weight))\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2) Dataset\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class Cars(Dataset):\n",
        "    def __init__(self, root, split, tf):\n",
        "        self.root = os.path.join(root, split)\n",
        "        self.tf   = tf\n",
        "        self.cls  = sorted(os.listdir(self.root))\n",
        "        self.c2i  = {c: i for i, c in enumerate(self.cls)}\n",
        "        self.samples = [\n",
        "            (os.path.join(self.root, c, f), self.c2i[c])\n",
        "            for c in self.cls\n",
        "            for f in os.listdir(os.path.join(self.root, c))\n",
        "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        p, y = self.samples[idx]\n",
        "        img  = Image.open(p).convert('RGB')\n",
        "        return self.tf(img), y\n",
        "    def classes(self): return self.cls\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3) Ana akÄ±ÅŸ\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def main():\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"PyTorch {torch.__version__} | CUDA {torch.version.cuda or '-'}\")\n",
        "\n",
        "    ROOT  = r\"C:\\Users\\User\\PycharmProjects\\Masin_model_detect\\balanv\\RoboFlow_Cars2\\cars_dataset_by_brand_3split\"\n",
        "    CKPT  = \"effb4_val70plus_ROBOFLOW_brend_BALANCED_augmented.pth\"\n",
        "    BATCH = 4\n",
        "    EPOCHS, LR = 60, 3e-4\n",
        "    torch.manual_seed(42); random.seed(42); np.random.seed(42)\n",
        "\n",
        "    # â”€â”€ DÃ¶nÃ¼ÅŸÃ¼mler\n",
        "    MEAN, STD = [0.485,0.456,0.406], [0.229,0.224,0.225]\n",
        "    train_tf = T.Compose([\n",
        "        T.RandomResizedCrop(380, scale=(0.7,1.0), ratio=(0.75,1.33)),\n",
        "        T.RandomHorizontalFlip(), T.ColorJitter(0.3,0.3,0.3,0.1),\n",
        "        T.RandomPerspective(0.2), T.ToTensor(), T.Normalize(MEAN, STD)\n",
        "    ])\n",
        "    val_tf = T.Compose([\n",
        "        T.Resize(400), T.CenterCrop(380),\n",
        "        T.ToTensor(), T.Normalize(MEAN, STD)\n",
        "    ])\n",
        "\n",
        "    # â”€â”€ KÃ¼meleri oku (artÄ±k hazÄ±r klasÃ¶rler)\n",
        "    train_ds = Cars(ROOT, 'train',  train_tf)\n",
        "    val_ds   = Cars(ROOT, 'valid',  val_tf)\n",
        "    test_ds  = Cars(ROOT, 'test',   val_tf)\n",
        "\n",
        "    n_cls = len(train_ds.classes())\n",
        "    print(\"SÄ±nÄ±f sayÄ±sÄ± :\", n_cls, \"| Train Ã¶rnek:\", len(train_ds),\n",
        "          \"| Valid:\", len(val_ds), \"| Test:\", len(test_ds))\n",
        "\n",
        "    # â”€â”€ DataLoaderâ€™lar\n",
        "    dl_kw = dict(batch_size=BATCH, num_workers=2, pin_memory=True)\n",
        "    train_dl = DataLoader(train_ds, shuffle=True,  **dl_kw)\n",
        "    val_dl   = DataLoader(val_ds,   shuffle=False, **dl_kw)\n",
        "    test_dl  = DataLoader(test_ds,  shuffle=False, **dl_kw)\n",
        "\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    # 4) Model\n",
        "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    backbone = timm.create_model('efficientnet_b4', pretrained=True,\n",
        "                                 num_classes=0).to(DEVICE)\n",
        "    backbone.global_pool = GeM().to(DEVICE)\n",
        "    head = ArcMarginProduct(backbone.num_features, n_cls, s=30., m=0.40).to(DEVICE)\n",
        "\n",
        "    crit  = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    opt   = torch.optim.AdamW(\n",
        "        list(backbone.parameters())+list(head.parameters()),\n",
        "        lr=LR, weight_decay=1e-2)\n",
        "    sched  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=DEVICE.type=='cuda')\n",
        "\n",
        "    # â”€â”€ DÃ¶ngÃ¼\n",
        "    def run(loader, train=True):\n",
        "        backbone.train(train); head.train(train)\n",
        "        tot = loss_sum = corr = 0\n",
        "        for step, (x,y) in enumerate(tqdm(loader, leave=False)):\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast(enabled=DEVICE.type=='cuda'):\n",
        "                feats  = backbone(x); logits = head(feats, y)\n",
        "                loss   = crit(logits, y)\n",
        "            if train:\n",
        "                opt.zero_grad(); scaler.scale(loss).backward()\n",
        "                scaler.step(opt); scaler.update()\n",
        "            loss_sum += loss.item()*x.size(0)\n",
        "            corr     += (logits.argmax(1)==y).sum().item()\n",
        "            tot      += x.size(0)\n",
        "        return loss_sum/tot, 100.*corr/tot\n",
        "\n",
        "    best_val = 0.\n",
        "    for ep in range(1, EPOCHS+1):\n",
        "        print(f\"\\nðŸŸ¢ Epoch {ep:02d}/{EPOCHS}\")\n",
        "        tl, ta = run(train_dl, True)\n",
        "        vl, va = run(val_dl,   False)\n",
        "        sched.step()\n",
        "\n",
        "        print(f\"E{ep:02d} | tr {ta:5.1f}% | val {va:5.1f}%\")\n",
        "        if va>=70 and va>best_val:\n",
        "            best_val = va\n",
        "            torch.save({'backbone': backbone.state_dict(),\n",
        "                        'head': head.state_dict(),\n",
        "                        'val_acc': va, 'epoch': ep}, CKPT)\n",
        "            print(f\" ðŸ’¾  {va:4.1f}% â‰¥70 â†’ kaydedildi ({CKPT})\")\n",
        "\n",
        "    # â”€â”€ En iyi modeli yÃ¼kle & test\n",
        "    if os.path.exists(CKPT):\n",
        "        ckpt = torch.load(CKPT, map_location=DEVICE)\n",
        "        backbone.load_state_dict(ckpt['backbone'])\n",
        "        head.load_state_dict(ckpt['head'])\n",
        "        print(f\"\\nEn iyi model: epoch {ckpt['epoch']} | val {ckpt['val_acc']:.1f}%\")\n",
        "\n",
        "    _, test_acc = run(test_dl, False)\n",
        "    print(f\"\\nTest top-1 : {test_acc:.2f}%\")\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if __name__ == \"__main__\":\n",
        "    import torch.multiprocessing as mp\n",
        "    mp.set_start_method(\"spawn\", force=True)\n",
        "    main()\n"
      ]
    }
  ]
}