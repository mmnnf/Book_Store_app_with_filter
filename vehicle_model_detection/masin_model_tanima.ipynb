{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJkkomWK8E4L5cyCmfuZUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmnnf/Book_Store_app_with_filter/blob/main/vehicle_model_detection/masin_model_tanima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cN4P0tn0N8P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch  : {torch.__version__}\")\n",
        "print(f\"CUDA sür.: {torch.version.cuda}\")\n",
        "print(f\"GPU      : {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'YOK'}\")\n",
        "\n",
        "import os, math, json, random, shutil, numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import torchvision.transforms as T, timm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('timm version :', timm.__version__)\n",
        "\n",
        "# ===============================================================\n",
        "# 1)  GeM  &  ArcMarginProduct  (fallback)\n",
        "# ===============================================================\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3., eps=1e-6): super().__init__(); self.p = nn.Parameter(torch.ones(1)*p); self.eps=eps\n",
        "    def forward(self,x): return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p),\n",
        "                                            (x.size(-2),x.size(-1))).pow(1./self.p)[:, :, 0, 0]\n",
        "\n",
        "try:\n",
        "    from timm.layers import ArcMarginProduct          # timm 0.8+\n",
        "except ImportError:\n",
        "    class ArcMarginProduct(nn.Module):                # basit fallback\n",
        "        def __init__(self,f_in,f_out,s=30.,m=0.4):   super().__init__(); self.s=s; self.m=m\n",
        "        def forward(self,x,y):                        # sadece logits üretmek yeterli\n",
        "            return x                                  # eğitim için CrossEntropy kullanıyoruz\n",
        "\n",
        "# ===============================================================\n",
        "# 2) Yol & Hyperparam\n",
        "# ===============================================================\n",
        "ROOT = 'stanford_cars_extracted'   # drive’daki “train / test”\n",
        "CKPT = 'car_b4_arc_best.pth'\n",
        "BATCH, EPOCHS, LR = 4, 60, 3e-4\n",
        "MEAN,STD = [0.485,0.456,0.406],[0.229,0.224,0.225]\n",
        "torch.manual_seed(42); np.random.seed(42); random.seed(42)\n",
        "\n",
        "# ===============================================================\n",
        "# 3) Dataset\n",
        "# ===============================================================\n",
        "class Cars(Dataset):\n",
        "    def __init__(self, root, split, tf):\n",
        "        self.root=os.path.join(root, split); self.tf=tf\n",
        "        self.cls = sorted(os.listdir(self.root))\n",
        "        self.c2i={c:i for i,c in enumerate(self.cls)}\n",
        "        self.samples=[(os.path.join(self.root,c,f), self.c2i[c])\n",
        "                      for c in self.cls\n",
        "                      for f in os.listdir(os.path.join(self.root,c))\n",
        "                      if f.lower().endswith(('jpg','png','jpeg'))]\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self,i):\n",
        "        p,y=self.samples[i]; img=Image.open(p).convert('RGB')\n",
        "        return self.tf(img), y\n",
        "    def classes(self): return self.cls\n",
        "\n",
        "train_tf = T.Compose([\n",
        "    T.RandomResizedCrop(380,scale=(0.7,1.0),ratio=(0.75,1.33)),\n",
        "    T.RandomHorizontalFlip(), T.ColorJitter(0.3,0.3,0.3,0.1),\n",
        "    T.RandomPerspective(0.2), T.ToTensor(), T.Normalize(MEAN,STD)\n",
        "])\n",
        "val_tf = T.Compose([T.Resize(400),T.CenterCrop(380),\n",
        "                    T.ToTensor(),T.Normalize(MEAN,STD)])\n",
        "\n",
        "full = Cars(ROOT,'train',train_tf)\n",
        "n_cls = len(full.classes());  print('Sınıf sayısı :', n_cls)\n",
        "val_len = len(full)//10; train_len=len(full)-val_len\n",
        "train_ds,val_ds=random_split(full,[train_len,val_len],\n",
        "                             generator=torch.Generator().manual_seed(42))\n",
        "val_ds.dataset.tf = val_tf\n",
        "test_ds = Cars(ROOT,'test', val_tf)\n",
        "\n",
        "dl_kw=dict(batch_size=BATCH, num_workers=0, pin_memory=False)\n",
        "train_dl=DataLoader(train_ds,shuffle=True, **dl_kw)\n",
        "val_dl  =DataLoader(val_ds,shuffle=False,**dl_kw)\n",
        "test_dl =DataLoader(test_ds,shuffle=False,**dl_kw)\n",
        "\n",
        "# ===============================================================\n",
        "# 4) Model  (Eff-B4 + GeM + ArcFace)\n",
        "# ===============================================================\n",
        "backbone = timm.create_model('efficientnet_b4',\n",
        "                             pretrained=True, num_classes=0).to(DEVICE)\n",
        "backbone.global_pool = GeM()                     # ← GeM havuzu eklendi\n",
        "head = ArcMarginProduct(backbone.num_features, n_cls,\n",
        "                        s=30., m=0.4).to(DEVICE)\n",
        "\n",
        "\n",
        "backbone.global_pool = GeM().to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    list(backbone.parameters())+list(head.parameters()),\n",
        "    lr=LR, weight_decay=1e-2)\n",
        "sched = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer, T_max=EPOCHS)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE.type=='cuda'))\n",
        "\n",
        "# def run(dl, train=True):\n",
        "#     backbone.train(train); head.train(train)\n",
        "#     tot=loss_sum=correct=0\n",
        "#     for x,y in tqdm(dl, leave=False):\n",
        "#         x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "#         with torch.cuda.amp.autocast(enabled=(DEVICE.type=='cuda')):\n",
        "#             feats = backbone(x)\n",
        "#             logits= head(feats,y)\n",
        "#             loss  = criterion(logits,y)\n",
        "#         if train:\n",
        "#             optimizer.zero_grad(); scaler.scale(loss).backward()\n",
        "#             scaler.step(optimizer); scaler.update()\n",
        "#         loss_sum += loss.item()*x.size(0)\n",
        "#         correct  += (logits.argmax(1)==y).sum().item(); tot+=x.size(0)\n",
        "#     return loss_sum/tot, correct/tot*100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run(dl, train=True):\n",
        "    backbone.train(train)\n",
        "    head.train(train)\n",
        "\n",
        "    tot = 0\n",
        "    loss_sum = 0.0\n",
        "    correct  = 0\n",
        "\n",
        "    for step, (x, y) in enumerate(tqdm(dl, leave=False)):\n",
        "        # ----  DEVICE KONTROLÜ – yalnızca ilk adımda ---------------\n",
        "        if step == 0:\n",
        "            print(\"❯ Batch tensor device :\", x.device)\n",
        "            print(\"❯ Backbone first weight :\", next(backbone.parameters()).device)\n",
        "            if DEVICE.type == 'cuda':\n",
        "                print(\"❯ GPU bellek (MB)     :\", round(torch.cuda.memory_allocated() / 1e6, 1))\n",
        "        # ------------------------------------------------------------\n",
        "\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE.type == 'cuda')):\n",
        "            feats  = backbone(x)\n",
        "            logits = head(feats, y)\n",
        "            loss   = criterion(logits, y)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        correct  += (logits.argmax(1) == y).sum().item()\n",
        "        tot      += x.size(0)\n",
        "\n",
        "    return loss_sum / tot, correct / tot * 100\n",
        "\n",
        "\n",
        "best=0\n",
        "for ep in range(1,EPOCHS+1):\n",
        "    tl,ta = run(train_dl,True)\n",
        "    vl,va = run(val_dl,False)\n",
        "    sched.step()\n",
        "    print(f\"E{ep:02d}  tr:{ta:5.1f}%  val:{va:5.1f}%\")\n",
        "    if va>best:\n",
        "        best=va\n",
        "        torch.save({'b':backbone.state_dict(),'h':head.state_dict()},\n",
        "                   CKPT)\n",
        "        print(f\"  ✔ New best {best:.1f}% saved\")\n",
        "\n",
        "# ===============================================================\n",
        "# 5) Test\n",
        "# ===============================================================\n",
        "ckpt=torch.load(CKPT,map_location=DEVICE)\n",
        "backbone.load_state_dict(ckpt['b']); head.load_state_dict(ckpt['h'])\n",
        "_,test_acc = run(test_dl,False)\n",
        "print(f\"\\nTest top-1 : {test_acc:.2f}%\")\n",
        "\n",
        "y_true=y_pred=[]\n",
        "backbone.eval(); head.eval()\n",
        "with torch.no_grad():\n",
        "    for x,y in test_dl:\n",
        "        logits=head(backbone(x.to(DEVICE)),y.to(DEVICE))\n",
        "        y_true.extend(y.numpy()); y_pred.extend(logits.argmax(1).cpu().numpy())\n",
        "print(classification_report(y_true,y_pred,target_names=full.classes()))\n"
      ]
    }
  ]
}